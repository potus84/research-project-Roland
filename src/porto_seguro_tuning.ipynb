{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Porto Seguro dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import xgboost\n",
    "import copy\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/tai/Projects/research-project-Roland')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/porto_seguro/porto_seguro.0.train\", encoding='latin1',\n",
    "                 na_values='?',\n",
    "                 names=['id',\n",
    "                 'target',\n",
    "                 'ps_ind_01',\n",
    "                 'ps_ind_02_cat',\n",
    "                 'ps_ind_03',\n",
    "                 'ps_ind_04_cat',\n",
    "                 'ps_ind_05_cat',\n",
    "                 'ps_ind_06_bin',\n",
    "                 'ps_ind_07_bin',\n",
    "                 'ps_ind_08_bin',\n",
    "                 'ps_ind_09_bin',\n",
    "                 'ps_ind_10_bin',\n",
    "                 'ps_ind_11_bin',\n",
    "                 'ps_ind_12_bin',\n",
    "                 'ps_ind_13_bin',\n",
    "                 'ps_ind_14',\n",
    "                 'ps_ind_15',\n",
    "                 'ps_ind_16_bin',\n",
    "                 'ps_ind_17_bin',\n",
    "                 'ps_ind_18_bin',\n",
    "                 'ps_reg_01',\n",
    "                 'ps_reg_02',\n",
    "                 'ps_reg_03',\n",
    "                 'ps_car_01_cat',\n",
    "                 'ps_car_02_cat',\n",
    "                 'ps_car_03_cat',\n",
    "                 'ps_car_04_cat',\n",
    "                 'ps_car_05_cat',\n",
    "                 'ps_car_06_cat',\n",
    "                 'ps_car_07_cat',\n",
    "                 'ps_car_08_cat',\n",
    "                 'ps_car_09_cat',\n",
    "                 'ps_car_10_cat',\n",
    "                 'ps_car_11_cat',\n",
    "                 'ps_car_11',\n",
    "                 'ps_car_12',\n",
    "                 'ps_car_13',\n",
    "                 'ps_car_14',\n",
    "                 'ps_car_15',\n",
    "                 'ps_calc_01',\n",
    "                 'ps_calc_02',\n",
    "                 'ps_calc_03',\n",
    "                 'ps_calc_04',\n",
    "                 'ps_calc_05',\n",
    "                 'ps_calc_06',\n",
    "                 'ps_calc_07',\n",
    "                 'ps_calc_08',\n",
    "                 'ps_calc_09',\n",
    "                 'ps_calc_10',\n",
    "                 'ps_calc_11',\n",
    "                 'ps_calc_12',\n",
    "                 'ps_calc_13',\n",
    "                 'ps_calc_14',\n",
    "                 'ps_calc_15_bin',\n",
    "                 'ps_calc_16_bin',\n",
    "                 'ps_calc_17_bin',\n",
    "                 'ps_calc_18_bin',\n",
    "                 'ps_calc_19_bin',\n",
    "                 'ps_calc_20_bin'],\n",
    "                 low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>169399</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146949</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54918</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1160514</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48624</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>304385</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1083903</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>605921</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1058435</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>648880</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0   169399       1          1            3.0          9            0.0   \n",
       "1   146949       1          7            1.0          6            0.0   \n",
       "2    54918       0          1            1.0          4            0.0   \n",
       "3  1160514       0          0            1.0         11            0.0   \n",
       "4    48624       1          6            1.0          8            1.0   \n",
       "5   304385       1          3            4.0          7            1.0   \n",
       "6  1083903       1          0            2.0          0            0.0   \n",
       "7   605921       0          5            1.0          4            1.0   \n",
       "8  1058435       1          1            1.0          3            1.0   \n",
       "9   648880       1          3            1.0          6            0.0   \n",
       "\n",
       "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ...  \\\n",
       "0            0.0              0              0              0  ...   \n",
       "1            6.0              0              1              0  ...   \n",
       "2            3.0              1              0              0  ...   \n",
       "3            0.0              0              0              0  ...   \n",
       "4            0.0              0              0              1  ...   \n",
       "5            0.0              0              1              0  ...   \n",
       "6            0.0              0              1              0  ...   \n",
       "7            0.0              0              1              0  ...   \n",
       "8            0.0              0              0              1  ...   \n",
       "9            0.0              0              1              0  ...   \n",
       "\n",
       "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           6           3           1           6               0   \n",
       "1           2           3           5           8               0   \n",
       "2           9           2           0           6               0   \n",
       "3           5           1           0           6               0   \n",
       "4           4           4           6           6               0   \n",
       "5          11           1           2           2               0   \n",
       "6          10           0           1           8               1   \n",
       "7           8           1           2           6               0   \n",
       "8           1           4           5           5               0   \n",
       "9           5           4           2           8               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               0               0               1   \n",
       "1               1               0               0               0   \n",
       "2               1               0               0               0   \n",
       "3               1               1               1               1   \n",
       "4               1               1               0               1   \n",
       "5               1               0               0               1   \n",
       "6               0               1               0               1   \n",
       "7               1               0               0               1   \n",
       "8               1               1               1               1   \n",
       "9               1               1               1               1   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               0  \n",
       "1               1  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "5               1  \n",
       "6               0  \n",
       "7               1  \n",
       "8               0  \n",
       "9               0  \n",
       "\n",
       "[10 rows x 59 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data/porto_seguro/porto_seguro.0.test\", encoding='latin1', \n",
    "                 names=['id',\n",
    "                 'target',\n",
    "                 'ps_ind_01',\n",
    "                 'ps_ind_02_cat',\n",
    "                 'ps_ind_03',\n",
    "                 'ps_ind_04_cat',\n",
    "                 'ps_ind_05_cat',\n",
    "                 'ps_ind_06_bin',\n",
    "                 'ps_ind_07_bin',\n",
    "                 'ps_ind_08_bin',\n",
    "                 'ps_ind_09_bin',\n",
    "                 'ps_ind_10_bin',\n",
    "                 'ps_ind_11_bin',\n",
    "                 'ps_ind_12_bin',\n",
    "                 'ps_ind_13_bin',\n",
    "                 'ps_ind_14',\n",
    "                 'ps_ind_15',\n",
    "                 'ps_ind_16_bin',\n",
    "                 'ps_ind_17_bin',\n",
    "                 'ps_ind_18_bin',\n",
    "                 'ps_reg_01',\n",
    "                 'ps_reg_02',\n",
    "                 'ps_reg_03',\n",
    "                 'ps_car_01_cat',\n",
    "                 'ps_car_02_cat',\n",
    "                 'ps_car_03_cat',\n",
    "                 'ps_car_04_cat',\n",
    "                 'ps_car_05_cat',\n",
    "                 'ps_car_06_cat',\n",
    "                 'ps_car_07_cat',\n",
    "                 'ps_car_08_cat',\n",
    "                 'ps_car_09_cat',\n",
    "                 'ps_car_10_cat',\n",
    "                 'ps_car_11_cat',\n",
    "                 'ps_car_11',\n",
    "                 'ps_car_12',\n",
    "                 'ps_car_13',\n",
    "                 'ps_car_14',\n",
    "                 'ps_car_15',\n",
    "                 'ps_calc_01',\n",
    "                 'ps_calc_02',\n",
    "                 'ps_calc_03',\n",
    "                 'ps_calc_04',\n",
    "                 'ps_calc_05',\n",
    "                 'ps_calc_06',\n",
    "                 'ps_calc_07',\n",
    "                 'ps_calc_08',\n",
    "                 'ps_calc_09',\n",
    "                 'ps_calc_10',\n",
    "                 'ps_calc_11',\n",
    "                 'ps_calc_12',\n",
    "                 'ps_calc_13',\n",
    "                 'ps_calc_14',\n",
    "                 'ps_calc_15_bin',\n",
    "                 'ps_calc_16_bin',\n",
    "                 'ps_calc_17_bin',\n",
    "                 'ps_calc_18_bin',\n",
    "                 'ps_calc_19_bin',\n",
    "                 'ps_calc_20_bin'],\n",
    "                 na_values='?',\n",
    "                 low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    0\n",
       "target                0\n",
       "ps_ind_01             0\n",
       "ps_ind_02_cat        22\n",
       "ps_ind_03             0\n",
       "ps_ind_04_cat        16\n",
       "ps_ind_05_cat       355\n",
       "ps_ind_06_bin         0\n",
       "ps_ind_07_bin         0\n",
       "ps_ind_08_bin         0\n",
       "ps_ind_09_bin         0\n",
       "ps_ind_10_bin         0\n",
       "ps_ind_11_bin         0\n",
       "ps_ind_12_bin         0\n",
       "ps_ind_13_bin         0\n",
       "ps_ind_14             0\n",
       "ps_ind_15             0\n",
       "ps_ind_16_bin         0\n",
       "ps_ind_17_bin         0\n",
       "ps_ind_18_bin         0\n",
       "ps_reg_01             0\n",
       "ps_reg_02             0\n",
       "ps_reg_03          3489\n",
       "ps_car_01_cat        17\n",
       "ps_car_02_cat         0\n",
       "ps_car_03_cat     14249\n",
       "ps_car_04_cat         0\n",
       "ps_car_05_cat      9105\n",
       "ps_car_06_cat         0\n",
       "ps_car_07_cat       674\n",
       "ps_car_08_cat         0\n",
       "ps_car_09_cat        36\n",
       "ps_car_10_cat         0\n",
       "ps_car_11_cat         0\n",
       "ps_car_11             0\n",
       "ps_car_12             0\n",
       "ps_car_13             0\n",
       "ps_car_14          1618\n",
       "ps_car_15             0\n",
       "ps_calc_01            0\n",
       "ps_calc_02            0\n",
       "ps_calc_03            0\n",
       "ps_calc_04            0\n",
       "ps_calc_05            0\n",
       "ps_calc_06            0\n",
       "ps_calc_07            0\n",
       "ps_calc_08            0\n",
       "ps_calc_09            0\n",
       "ps_calc_10            0\n",
       "ps_calc_11            0\n",
       "ps_calc_12            0\n",
       "ps_calc_13            0\n",
       "ps_calc_14            0\n",
       "ps_calc_15_bin        0\n",
       "ps_calc_16_bin        0\n",
       "ps_calc_17_bin        0\n",
       "ps_calc_18_bin        0\n",
       "ps_calc_19_bin        0\n",
       "ps_calc_20_bin        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    0\n",
       "target                0\n",
       "ps_ind_01             0\n",
       "ps_ind_02_cat        26\n",
       "ps_ind_03             0\n",
       "ps_ind_04_cat        19\n",
       "ps_ind_05_cat       315\n",
       "ps_ind_06_bin         0\n",
       "ps_ind_07_bin         0\n",
       "ps_ind_08_bin         0\n",
       "ps_ind_09_bin         0\n",
       "ps_ind_10_bin         0\n",
       "ps_ind_11_bin         0\n",
       "ps_ind_12_bin         0\n",
       "ps_ind_13_bin         0\n",
       "ps_ind_14             0\n",
       "ps_ind_15             0\n",
       "ps_ind_16_bin         0\n",
       "ps_ind_17_bin         0\n",
       "ps_ind_18_bin         0\n",
       "ps_reg_01             0\n",
       "ps_reg_02             0\n",
       "ps_reg_03          3560\n",
       "ps_car_01_cat        19\n",
       "ps_car_02_cat         0\n",
       "ps_car_03_cat     14335\n",
       "ps_car_04_cat         0\n",
       "ps_car_05_cat      9173\n",
       "ps_car_06_cat         0\n",
       "ps_car_07_cat       615\n",
       "ps_car_08_cat         0\n",
       "ps_car_09_cat        37\n",
       "ps_car_10_cat         0\n",
       "ps_car_11_cat         0\n",
       "ps_car_11             1\n",
       "ps_car_12             0\n",
       "ps_car_13             0\n",
       "ps_car_14          1623\n",
       "ps_car_15             0\n",
       "ps_calc_01            0\n",
       "ps_calc_02            0\n",
       "ps_calc_03            0\n",
       "ps_calc_04            0\n",
       "ps_calc_05            0\n",
       "ps_calc_06            0\n",
       "ps_calc_07            0\n",
       "ps_calc_08            0\n",
       "ps_calc_09            0\n",
       "ps_calc_10            0\n",
       "ps_calc_11            0\n",
       "ps_calc_12            0\n",
       "ps_calc_13            0\n",
       "ps_calc_14            0\n",
       "ps_calc_15_bin        0\n",
       "ps_calc_16_bin        0\n",
       "ps_calc_17_bin        0\n",
       "ps_calc_18_bin        0\n",
       "ps_calc_19_bin        0\n",
       "ps_calc_20_bin        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21696 entries, 0 to 21695\n",
      "Data columns (total 59 columns):\n",
      "id                21696 non-null int64\n",
      "target            21696 non-null int64\n",
      "ps_ind_01         21696 non-null int64\n",
      "ps_ind_02_cat     21670 non-null float64\n",
      "ps_ind_03         21696 non-null int64\n",
      "ps_ind_04_cat     21677 non-null float64\n",
      "ps_ind_05_cat     21381 non-null float64\n",
      "ps_ind_06_bin     21696 non-null int64\n",
      "ps_ind_07_bin     21696 non-null int64\n",
      "ps_ind_08_bin     21696 non-null int64\n",
      "ps_ind_09_bin     21696 non-null int64\n",
      "ps_ind_10_bin     21696 non-null int64\n",
      "ps_ind_11_bin     21696 non-null int64\n",
      "ps_ind_12_bin     21696 non-null int64\n",
      "ps_ind_13_bin     21696 non-null int64\n",
      "ps_ind_14         21696 non-null int64\n",
      "ps_ind_15         21696 non-null int64\n",
      "ps_ind_16_bin     21696 non-null int64\n",
      "ps_ind_17_bin     21696 non-null int64\n",
      "ps_ind_18_bin     21696 non-null int64\n",
      "ps_reg_01         21696 non-null float64\n",
      "ps_reg_02         21696 non-null float64\n",
      "ps_reg_03         18136 non-null float64\n",
      "ps_car_01_cat     21677 non-null float64\n",
      "ps_car_02_cat     21696 non-null int64\n",
      "ps_car_03_cat     7361 non-null float64\n",
      "ps_car_04_cat     21696 non-null int64\n",
      "ps_car_05_cat     12523 non-null float64\n",
      "ps_car_06_cat     21696 non-null int64\n",
      "ps_car_07_cat     21081 non-null float64\n",
      "ps_car_08_cat     21696 non-null int64\n",
      "ps_car_09_cat     21659 non-null float64\n",
      "ps_car_10_cat     21696 non-null int64\n",
      "ps_car_11_cat     21696 non-null int64\n",
      "ps_car_11         21695 non-null float64\n",
      "ps_car_12         21696 non-null float64\n",
      "ps_car_13         21696 non-null float64\n",
      "ps_car_14         20073 non-null float64\n",
      "ps_car_15         21696 non-null float64\n",
      "ps_calc_01        21696 non-null float64\n",
      "ps_calc_02        21696 non-null float64\n",
      "ps_calc_03        21696 non-null float64\n",
      "ps_calc_04        21696 non-null int64\n",
      "ps_calc_05        21696 non-null int64\n",
      "ps_calc_06        21696 non-null int64\n",
      "ps_calc_07        21696 non-null int64\n",
      "ps_calc_08        21696 non-null int64\n",
      "ps_calc_09        21696 non-null int64\n",
      "ps_calc_10        21696 non-null int64\n",
      "ps_calc_11        21696 non-null int64\n",
      "ps_calc_12        21696 non-null int64\n",
      "ps_calc_13        21696 non-null int64\n",
      "ps_calc_14        21696 non-null int64\n",
      "ps_calc_15_bin    21696 non-null int64\n",
      "ps_calc_16_bin    21696 non-null int64\n",
      "ps_calc_17_bin    21696 non-null int64\n",
      "ps_calc_18_bin    21696 non-null int64\n",
      "ps_calc_19_bin    21696 non-null int64\n",
      "ps_calc_20_bin    21696 non-null int64\n",
      "dtypes: float64(19), int64(40)\n",
      "memory usage: 9.8 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.get_dummies(train, columns=[ 'ps_car_02_cat',\n",
    "#                                          'ps_car_04_cat',\n",
    "#                                          'ps_car_06_cat',\n",
    "#                                          'ps_car_08_cat',\n",
    "#                                          'ps_car_10_cat',\n",
    "#                                          'ps_car_11_cat'])\n",
    "# train = pd.get_dummies(train, columns=[\n",
    "#     'ps_ind_02_cat',\n",
    "#     'ps_ind_04_cat',\n",
    "#     'ps_ind_05_cat',\n",
    "#     'ps_car_01_cat',\n",
    "#     'ps_car_03_cat',\n",
    "#     'ps_car_05_cat',\n",
    "#     'ps_car_07_cat',\n",
    "#     'ps_car_09_cat'\n",
    "# ], dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.get_dummies(test, columns=[ 'ps_car_02_cat',\n",
    "#                                          'ps_car_04_cat',\n",
    "#                                          'ps_car_06_cat',\n",
    "#                                          'ps_car_08_cat',\n",
    "#                                          'ps_car_10_cat',\n",
    "#                                          'ps_car_11_cat'])\n",
    "# test = pd.get_dummies(test, columns=[\n",
    "#     'ps_ind_02_cat',\n",
    "#     'ps_ind_04_cat',\n",
    "#     'ps_ind_05_cat',\n",
    "#     'ps_car_01_cat',\n",
    "#     'ps_car_03_cat',\n",
    "#     'ps_car_05_cat',\n",
    "#     'ps_car_07_cat',\n",
    "#     'ps_car_09_cat'\n",
    "# ], dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['target', 'id'], axis=1)\n",
    "y_train = train.target\n",
    "\n",
    "X_test = test.drop(['target', 'id'], axis=1)\n",
    "y_test = test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test = X_train.align(X_test, join='outer', fill_value=0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21696, 57)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21696, 57)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ps_ind_01', 'ps_ind_02_cat', 'ps_ind_03', 'ps_ind_04_cat',\n",
       "       'ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin',\n",
       "       'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin',\n",
       "       'ps_ind_13_bin', 'ps_ind_14', 'ps_ind_15', 'ps_ind_16_bin',\n",
       "       'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_reg_01', 'ps_reg_02', 'ps_reg_03',\n",
       "       'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat',\n",
       "       'ps_car_05_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat',\n",
       "       'ps_car_09_cat', 'ps_car_10_cat', 'ps_car_11_cat', 'ps_car_11',\n",
       "       'ps_car_12', 'ps_car_13', 'ps_car_14', 'ps_car_15', 'ps_calc_01',\n",
       "       'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05', 'ps_calc_06',\n",
       "       'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10', 'ps_calc_11',\n",
       "       'ps_calc_12', 'ps_calc_13', 'ps_calc_14', 'ps_calc_15_bin',\n",
       "       'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin', 'ps_calc_19_bin',\n",
       "       'ps_calc_20_bin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ps_ind_01', 'ps_ind_02_cat', 'ps_ind_03', 'ps_ind_04_cat',\n",
       "       'ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin',\n",
       "       'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin',\n",
       "       'ps_ind_13_bin', 'ps_ind_14', 'ps_ind_15', 'ps_ind_16_bin',\n",
       "       'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_reg_01', 'ps_reg_02', 'ps_reg_03',\n",
       "       'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat',\n",
       "       'ps_car_05_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat',\n",
       "       'ps_car_09_cat', 'ps_car_10_cat', 'ps_car_11_cat', 'ps_car_11',\n",
       "       'ps_car_12', 'ps_car_13', 'ps_car_14', 'ps_car_15', 'ps_calc_01',\n",
       "       'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05', 'ps_calc_06',\n",
       "       'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10', 'ps_calc_11',\n",
       "       'ps_calc_12', 'ps_calc_13', 'ps_calc_14', 'ps_calc_15_bin',\n",
       "       'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin', 'ps_calc_19_bin',\n",
       "       'ps_calc_20_bin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Tuning on train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find optimal n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.414800</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.435887</td>\n",
       "      <td>0.003168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.407898</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>0.430678</td>\n",
       "      <td>0.003672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.401756</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.423995</td>\n",
       "      <td>0.003579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.397147</td>\n",
       "      <td>0.001263</td>\n",
       "      <td>0.423764</td>\n",
       "      <td>0.004604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.395303</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.421460</td>\n",
       "      <td>0.005344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.392987</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>0.419939</td>\n",
       "      <td>0.005495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.390222</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>0.417773</td>\n",
       "      <td>0.004257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.387698</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.419754</td>\n",
       "      <td>0.003935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.385658</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.416759</td>\n",
       "      <td>0.002964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.383780</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>0.416943</td>\n",
       "      <td>0.004710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.383481</td>\n",
       "      <td>0.005198</td>\n",
       "      <td>0.416805</td>\n",
       "      <td>0.004405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.380197</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>0.416436</td>\n",
       "      <td>0.003918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.378065</td>\n",
       "      <td>0.004617</td>\n",
       "      <td>0.417542</td>\n",
       "      <td>0.002823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.377143</td>\n",
       "      <td>0.003589</td>\n",
       "      <td>0.416759</td>\n",
       "      <td>0.004638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.375242</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.415606</td>\n",
       "      <td>0.004539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.374804</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.415145</td>\n",
       "      <td>0.004876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.373030</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.414224</td>\n",
       "      <td>0.004685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.372280</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>0.413394</td>\n",
       "      <td>0.003892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.371647</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.413071</td>\n",
       "      <td>0.004242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.370264</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>0.412933</td>\n",
       "      <td>0.007094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.368881</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.413348</td>\n",
       "      <td>0.005883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.367084</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>0.413117</td>\n",
       "      <td>0.006445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.366266</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.413117</td>\n",
       "      <td>0.007106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.364929</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>0.411873</td>\n",
       "      <td>0.006690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.363592</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>0.412794</td>\n",
       "      <td>0.007718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.363235</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>0.413393</td>\n",
       "      <td>0.005985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.361553</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.412333</td>\n",
       "      <td>0.006622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.360274</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.412472</td>\n",
       "      <td>0.005789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.358545</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.412564</td>\n",
       "      <td>0.006180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.357854</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.412149</td>\n",
       "      <td>0.004967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.356517</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>0.413209</td>\n",
       "      <td>0.006468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.354847</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.412887</td>\n",
       "      <td>0.006423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.353429</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.411780</td>\n",
       "      <td>0.005594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.352600</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.411274</td>\n",
       "      <td>0.006194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.351389</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.411412</td>\n",
       "      <td>0.005933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.350053</td>\n",
       "      <td>0.002718</td>\n",
       "      <td>0.410859</td>\n",
       "      <td>0.005575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.349143</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>0.410259</td>\n",
       "      <td>0.006366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.348175</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.410674</td>\n",
       "      <td>0.005939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.346999</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.410905</td>\n",
       "      <td>0.006456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.345260</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.410305</td>\n",
       "      <td>0.006530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.344107</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.410720</td>\n",
       "      <td>0.006620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.342851</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.409798</td>\n",
       "      <td>0.006284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.341883</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.409798</td>\n",
       "      <td>0.006716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.341353</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>0.410674</td>\n",
       "      <td>0.007635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.340351</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.410858</td>\n",
       "      <td>0.006956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.339256</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>0.411411</td>\n",
       "      <td>0.007076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.337965</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.410536</td>\n",
       "      <td>0.006974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.336675</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.410167</td>\n",
       "      <td>0.006645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.336410</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.409199</td>\n",
       "      <td>0.006971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.335499</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.408646</td>\n",
       "      <td>0.006978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-error-mean  train-error-std  test-error-mean  test-error-std\n",
       "0           0.414800         0.002250         0.435887        0.003168\n",
       "1           0.407898         0.002720         0.430678        0.003672\n",
       "2           0.401756         0.001675         0.423995        0.003579\n",
       "3           0.397147         0.001263         0.423764        0.004604\n",
       "4           0.395303         0.001451         0.421460        0.005344\n",
       "5           0.392987         0.003064         0.419939        0.005495\n",
       "6           0.390222         0.002785         0.417773        0.004257\n",
       "7           0.387698         0.002863         0.419754        0.003935\n",
       "8           0.385658         0.003625         0.416759        0.002964\n",
       "9           0.383780         0.005493         0.416943        0.004710\n",
       "10          0.383481         0.005198         0.416805        0.004405\n",
       "11          0.380197         0.004241         0.416436        0.003918\n",
       "12          0.378065         0.004617         0.417542        0.002823\n",
       "13          0.377143         0.003589         0.416759        0.004638\n",
       "14          0.375242         0.003000         0.415606        0.004539\n",
       "15          0.374804         0.002979         0.415145        0.004876\n",
       "16          0.373030         0.001598         0.414224        0.004685\n",
       "17          0.372280         0.001967         0.413394        0.003892\n",
       "18          0.371647         0.001473         0.413071        0.004242\n",
       "19          0.370264         0.001804         0.412933        0.007094\n",
       "20          0.368881         0.001989         0.413348        0.005883\n",
       "21          0.367084         0.001820         0.413117        0.006445\n",
       "22          0.366266         0.001677         0.413117        0.007106\n",
       "23          0.364929         0.002066         0.411873        0.006690\n",
       "24          0.363592         0.002152         0.412794        0.007718\n",
       "25          0.363235         0.002703         0.413393        0.005985\n",
       "26          0.361553         0.002290         0.412333        0.006622\n",
       "27          0.360274         0.001678         0.412472        0.005789\n",
       "28          0.358545         0.002014         0.412564        0.006180\n",
       "29          0.357854         0.002045         0.412149        0.004967\n",
       "30          0.356517         0.002173         0.413209        0.006468\n",
       "31          0.354847         0.001818         0.412887        0.006423\n",
       "32          0.353429         0.002361         0.411780        0.005594\n",
       "33          0.352600         0.002232         0.411274        0.006194\n",
       "34          0.351389         0.002349         0.411412        0.005933\n",
       "35          0.350053         0.002718         0.410859        0.005575\n",
       "36          0.349143         0.001533         0.410259        0.006366\n",
       "37          0.348175         0.001399         0.410674        0.005939\n",
       "38          0.346999         0.001556         0.410905        0.006456\n",
       "39          0.345260         0.002083         0.410305        0.006530\n",
       "40          0.344107         0.002192         0.410720        0.006620\n",
       "41          0.342851         0.001713         0.409798        0.006284\n",
       "42          0.341883         0.002078         0.409798        0.006716\n",
       "43          0.341353         0.002152         0.410674        0.007635\n",
       "44          0.340351         0.002326         0.410858        0.006956\n",
       "45          0.339256         0.002167         0.411411        0.007076\n",
       "46          0.337965         0.001925         0.410536        0.006974\n",
       "47          0.336675         0.002028         0.410167        0.006645\n",
       "48          0.336410         0.001798         0.409199        0.006971\n",
       "49          0.335499         0.002216         0.408646        0.006978"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=5000,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    n_jobs=-1)\n",
    "\n",
    "xgb_param = xgb.get_xgb_params()\n",
    "xgtrain = xgboost.DMatrix(X_train, label=y_train)\n",
    "\n",
    "\n",
    "xgboost.cv(xgb_param, xgtrain, num_boost_round=5000, nfold=5, metrics=['error'],\n",
    "     early_stopping_rounds=50, stratified=True, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10 times\n",
      "Run 0 best param:  {'max_depth': 7, 'min_child_weight': 151}\n",
      "Run 0 best score:  0.5945796460176991\n",
      "Run 1 best param:  {'max_depth': 5, 'min_child_weight': 51}\n",
      "Run 1 best score:  0.5935656342182891\n",
      "Run 2 best param:  {'max_depth': 7, 'min_child_weight': 201}\n",
      "Run 2 best score:  0.5935656342182891\n",
      "Run 3 best param:  {'max_depth': 3, 'min_child_weight': 51}\n",
      "Run 3 best score:  0.5914915191740413\n",
      "Run 4 best param:  {'max_depth': 7, 'min_child_weight': 151}\n",
      "Run 4 best score:  0.5935656342182891\n",
      "Run 5 best param:  {'max_depth': 7, 'min_child_weight': 101}\n",
      "Run 5 best score:  0.5911688790560472\n",
      "Run 6 best param:  {'max_depth': 5, 'min_child_weight': 101}\n",
      "Run 6 best score:  0.590523598820059\n",
      "Run 7 best param:  {'max_depth': 7, 'min_child_weight': 151}\n",
      "Run 7 best score:  0.5941648230088495\n",
      "Run 8 best param:  {'max_depth': 7, 'min_child_weight': 201}\n",
      "Run 8 best score:  0.5919063421828908\n",
      "Run 9 best param:  {'max_depth': 5, 'min_child_weight': 151}\n",
      "Run 9 best score:  0.5907079646017699\n",
      "Best params:  params               {'max_depth': 7, 'min_child_weight': 151}\n",
      "mean_test_score_0                                      0.59458\n",
      "mean_test_score_1                                     0.587343\n",
      "mean_test_score_2                                     0.589786\n",
      "mean_test_score_3                                     0.590293\n",
      "mean_test_score_4                                     0.593566\n",
      "mean_test_score_5                                     0.589463\n",
      "mean_test_score_6                                     0.590063\n",
      "mean_test_score_7                                     0.594165\n",
      "mean_test_score_8                                     0.591215\n",
      "mean_test_score_9                                     0.590155\n",
      "avg                                                   0.591063\n",
      "Name: 18, dtype: object\n"
     ]
    }
   ],
   "source": [
    "NUM_TRIALS = int(np.ceil(200000/train.shape[0]))\n",
    "param_test1 = {\n",
    " 'max_depth':range(1,10,2),\n",
    " 'min_child_weight':range(1,250,50)\n",
    "}\n",
    "# Grid search 1 cv result\n",
    "grid_score1 = pd.DataFrame()\n",
    "\n",
    "# Loop for each trial\n",
    "print('Run {} times'.format(NUM_TRIALS))\n",
    "for i in range(NUM_TRIALS):\n",
    "    xgb = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=49,\n",
    "        max_depth=5,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        n_jobs=-1,\n",
    "        seed=0)\n",
    "    five_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=i)\n",
    "    gsearch1 = GridSearchCV(estimator = xgb,\n",
    "                            param_grid = param_test1,\n",
    "                            scoring='accuracy',n_jobs=-1,\n",
    "                            cv=five_folds,\n",
    "                            return_train_score=False)\n",
    "    gsearch1.fit(X_train,y_train)    \n",
    "    if grid_score1.empty:\n",
    "        grid_score1 = pd.DataFrame(gsearch1.cv_results_, columns=['params', 'mean_test_score'])\n",
    "        grid_score1.columns = ['params', 'mean_test_score_0']\n",
    "    else:\n",
    "        grid_score1['mean_test_score_{}'.format(i)] = pd.DataFrame(gsearch1.cv_results_).mean_test_score\n",
    "    print('Run {} best param: '.format(i), gsearch1.best_params_)\n",
    "    print('Run {} best score: '.format(i), gsearch1.best_score_)\n",
    "\n",
    "grid_score1['avg'] = grid_score1.sum(axis=1)/NUM_TRIALS\n",
    "print('Best params: ', grid_score1.loc[grid_score1.avg.idxmax(), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10 times\n",
      "Run 0 best param:  {'max_depth': 9, 'min_child_weight': 150}\n",
      "Run 0 best score:  0.5954553834808259\n",
      "Run 1 best param:  {'max_depth': 5, 'min_child_weight': 170}\n",
      "Run 1 best score:  0.5919063421828908\n",
      "Run 2 best param:  {'max_depth': 7, 'min_child_weight': 220}\n",
      "Run 2 best score:  0.5941187315634219\n",
      "Run 3 best param:  {'max_depth': 5, 'min_child_weight': 210}\n",
      "Run 3 best score:  0.5928281710914455\n",
      "Run 4 best param:  {'max_depth': 7, 'min_child_weight': 150}\n",
      "Run 4 best score:  0.5934734513274337\n",
      "Run 5 best param:  {'max_depth': 5, 'min_child_weight': 170}\n",
      "Run 5 best score:  0.5930125368731564\n",
      "Run 6 best param:  {'max_depth': 9, 'min_child_weight': 150}\n",
      "Run 6 best score:  0.5919985250737463\n",
      "Run 7 best param:  {'max_depth': 7, 'min_child_weight': 190}\n",
      "Run 7 best score:  0.5943952802359882\n",
      "Run 8 best param:  {'max_depth': 7, 'min_child_weight': 200}\n",
      "Run 8 best score:  0.5950405604719764\n",
      "Run 9 best param:  {'max_depth': 7, 'min_child_weight': 230}\n",
      "Run 9 best score:  0.5908001474926253\n",
      "Best params:  params               {'max_depth': 5, 'min_child_weight': 170}\n",
      "mean_test_score_0                                     0.595087\n",
      "mean_test_score_1                                     0.591906\n",
      "mean_test_score_2                                     0.590339\n",
      "mean_test_score_3                                     0.589602\n",
      "mean_test_score_4                                     0.593059\n",
      "mean_test_score_5                                     0.593013\n",
      "mean_test_score_6                                     0.589095\n",
      "mean_test_score_7                                     0.591492\n",
      "mean_test_score_8                                     0.590524\n",
      "mean_test_score_9                                     0.588634\n",
      "avg                                                   0.591275\n",
      "Name: 22, dtype: object\n"
     ]
    }
   ],
   "source": [
    "NUM_TRIALS = int(np.ceil(200000/train.shape[0]))\n",
    "param_test1b = {\n",
    " 'max_depth':range(1,10,2),\n",
    " 'min_child_weight':range(150, 250, 10)\n",
    "}\n",
    "# Grid search 1 cv result\n",
    "grid_score1b = pd.DataFrame()\n",
    "\n",
    "# Loop for each trial\n",
    "print('Run {} times'.format(NUM_TRIALS))\n",
    "for i in range(NUM_TRIALS):\n",
    "    xgb = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=49,\n",
    "        max_depth=5,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        n_jobs=-1,\n",
    "        seed=0)\n",
    "    five_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=i)\n",
    "    gsearch1b = GridSearchCV(estimator = xgb,\n",
    "                            param_grid = param_test1b,\n",
    "                            scoring='accuracy',n_jobs=-1,\n",
    "                            cv=five_folds,\n",
    "                            return_train_score=False)\n",
    "    gsearch1b.fit(X_train,y_train)    \n",
    "    if grid_score1b.empty:\n",
    "        grid_score1b = pd.DataFrame(gsearch1b.cv_results_, columns=['params', 'mean_test_score'])\n",
    "        grid_score1b.columns = ['params', 'mean_test_score_0']\n",
    "    else:\n",
    "        grid_score1b['mean_test_score_{}'.format(i)] = pd.DataFrame(gsearch1b.cv_results_).mean_test_score\n",
    "    print('Run {} best param: '.format(i), gsearch1b.best_params_)\n",
    "    print('Run {} best score: '.format(i), gsearch1b.best_score_)\n",
    "\n",
    "grid_score1b['avg'] = grid_score1b.sum(axis=1)/NUM_TRIALS\n",
    "print('Best params: ', grid_score1b.loc[grid_score1b.avg.idxmax(), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10 times\n",
      "Run 0 best param:  {'max_depth': 5, 'min_child_weight': 165}\n",
      "Run 0 best score:  0.5953632005899705\n",
      "Run 1 best param:  {'max_depth': 6, 'min_child_weight': 161}\n",
      "Run 1 best score:  0.5922750737463127\n",
      "Run 2 best param:  {'max_depth': 5, 'min_child_weight': 163}\n",
      "Run 2 best score:  0.5922750737463127\n",
      "Run 3 best param:  {'max_depth': 6, 'min_child_weight': 162}\n",
      "Run 3 best score:  0.5919524336283186\n",
      "Run 4 best param:  {'max_depth': 6, 'min_child_weight': 164}\n",
      "Run 4 best score:  0.5946718289085545\n",
      "Run 5 best param:  {'max_depth': 6, 'min_child_weight': 165}\n",
      "Run 5 best score:  0.5943952802359882\n",
      "Run 6 best param:  {'max_depth': 5, 'min_child_weight': 160}\n",
      "Run 6 best score:  0.589832227138643\n",
      "Run 7 best param:  {'max_depth': 5, 'min_child_weight': 169}\n",
      "Run 7 best score:  0.5927359882005899\n",
      "Run 8 best param:  {'max_depth': 5, 'min_child_weight': 166}\n",
      "Run 8 best score:  0.592551622418879\n",
      "Run 9 best param:  {'max_depth': 6, 'min_child_weight': 161}\n",
      "Run 9 best score:  0.5926898967551623\n",
      "Best params:  params               {'max_depth': 6, 'min_child_weight': 161}\n",
      "mean_test_score_0                                     0.593473\n",
      "mean_test_score_1                                     0.592275\n",
      "mean_test_score_2                                     0.590293\n",
      "mean_test_score_3                                     0.590938\n",
      "mean_test_score_4                                     0.591261\n",
      "mean_test_score_5                                     0.591492\n",
      "mean_test_score_6                                     0.588219\n",
      "mean_test_score_7                                     0.591584\n",
      "mean_test_score_8                                       0.5908\n",
      "mean_test_score_9                                      0.59269\n",
      "avg                                                   0.591303\n",
      "Name: 23, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Look carefully again the neigbor values\n",
    "NUM_TRIALS = int(np.ceil(200000/train.shape[0]))\n",
    "param_test2 = {\n",
    " 'max_depth':[4, 5, 6],\n",
    " 'min_child_weight':range(160, 171)\n",
    "}\n",
    "# Grid search 1 cv result\n",
    "grid_score2 = pd.DataFrame()\n",
    "\n",
    "# Loop for each trial\n",
    "print('Run {} times'.format(NUM_TRIALS))\n",
    "for i in range(NUM_TRIALS):\n",
    "    xgb = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=49,\n",
    "        max_depth=5,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=1,        \n",
    "        seed=0)\n",
    "    five_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=i)\n",
    "    gsearch2 = GridSearchCV(estimator = xgb,\n",
    "                            param_grid = param_test2,\n",
    "                            scoring='accuracy',n_jobs=-1,\n",
    "                            cv=five_folds,\n",
    "                            return_train_score=False)\n",
    "    gsearch2.fit(X_train,y_train)    \n",
    "    if grid_score2.empty:\n",
    "        grid_score2 = pd.DataFrame(gsearch2.cv_results_, columns=['params', 'mean_test_score'])\n",
    "        grid_score2.columns = ['params', 'mean_test_score_0']\n",
    "    else:\n",
    "        grid_score2['mean_test_score_{}'.format(i)] = pd.DataFrame(gsearch2.cv_results_).mean_test_score\n",
    "    print('Run {} best param: '.format(i), gsearch2.best_params_)\n",
    "    print('Run {} best score: '.format(i), gsearch2.best_score_)\n",
    "\n",
    "grid_score2['avg'] = grid_score2.sum(axis=1)/NUM_TRIALS\n",
    "print('Best params: ', grid_score2.loc[grid_score2.avg.idxmax(), :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10 times\n",
      "Run 0 best param:  {'gamma': 0.2}\n",
      "Run 0 best score:  0.5936578171091446\n",
      "Run 1 best param:  {'gamma': 0.0}\n",
      "Run 1 best score:  0.5922750737463127\n",
      "Run 2 best param:  {'gamma': 0.4}\n",
      "Run 2 best score:  0.5907540560471977\n",
      "Run 3 best param:  {'gamma': 0.3}\n",
      "Run 3 best score:  0.5915837020648967\n",
      "Run 4 best param:  {'gamma': 0.0}\n",
      "Run 4 best score:  0.5912610619469026\n",
      "Run 5 best param:  {'gamma': 0.0}\n",
      "Run 5 best score:  0.5914915191740413\n",
      "Run 6 best param:  {'gamma': 0.4}\n",
      "Run 6 best score:  0.5884494837758112\n",
      "Run 7 best param:  {'gamma': 0.0}\n",
      "Run 7 best score:  0.5915837020648967\n",
      "Run 8 best param:  {'gamma': 0.3}\n",
      "Run 8 best score:  0.5908462389380531\n",
      "Run 9 best param:  {'gamma': 0.0}\n",
      "Run 9 best score:  0.5926898967551623\n",
      "Best params:  params               {'gamma': 0.1}\n",
      "mean_test_score_0          0.593427\n",
      "mean_test_score_1          0.592275\n",
      "mean_test_score_2          0.590293\n",
      "mean_test_score_3          0.590938\n",
      "mean_test_score_4          0.591261\n",
      "mean_test_score_5          0.591492\n",
      "mean_test_score_6          0.588265\n",
      "mean_test_score_7          0.591584\n",
      "mean_test_score_8            0.5908\n",
      "mean_test_score_9           0.59269\n",
      "avg                        0.591303\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "# Grid search 1 cv result\n",
    "grid_score3 = pd.DataFrame()\n",
    "\n",
    "# Loop for each trial\n",
    "print('Run {} times'.format(NUM_TRIALS))\n",
    "for i in range(NUM_TRIALS):\n",
    "    xgb = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=49,\n",
    "        max_depth=6,\n",
    "        min_child_weight=161,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=1,        \n",
    "        seed=0)\n",
    "    five_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=i)\n",
    "    gsearch3 = GridSearchCV(estimator = xgb,\n",
    "                            param_grid = param_test3,\n",
    "                            scoring='accuracy',n_jobs=-1,\n",
    "                            cv=five_folds,\n",
    "                            return_train_score=False)\n",
    "    gsearch3.fit(X_train,y_train)    \n",
    "    if grid_score3.empty:\n",
    "        grid_score3 = pd.DataFrame(gsearch3.cv_results_, columns=['params', 'mean_test_score'])\n",
    "        grid_score3.columns = ['params', 'mean_test_score_0']\n",
    "    else:\n",
    "        grid_score3['mean_test_score_{}'.format(i)] = pd.DataFrame(gsearch3.cv_results_).mean_test_score\n",
    "    print('Run {} best param: '.format(i), gsearch3.best_params_)\n",
    "    print('Run {} best score: '.format(i), gsearch3.best_score_)\n",
    "\n",
    "grid_score3['avg'] = grid_score3.sum(axis=1)/NUM_TRIALS\n",
    "print('Best params: ', grid_score3.loc[grid_score3.avg.idxmax(), :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recablirating the n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.421022</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.432521</td>\n",
       "      <td>0.005487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.414835</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.424824</td>\n",
       "      <td>0.004300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.410744</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.422197</td>\n",
       "      <td>0.004521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.408439</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.419846</td>\n",
       "      <td>0.006790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.406711</td>\n",
       "      <td>0.002886</td>\n",
       "      <td>0.421229</td>\n",
       "      <td>0.006079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.405651</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.420630</td>\n",
       "      <td>0.006465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.403980</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.421045</td>\n",
       "      <td>0.004949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.403865</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.417911</td>\n",
       "      <td>0.005358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.401963</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.417127</td>\n",
       "      <td>0.005718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.401618</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.415698</td>\n",
       "      <td>0.005775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.400869</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>0.415237</td>\n",
       "      <td>0.005184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.400004</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.413486</td>\n",
       "      <td>0.003710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.399947</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.413163</td>\n",
       "      <td>0.004833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.399843</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>0.412933</td>\n",
       "      <td>0.004772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.398311</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.412150</td>\n",
       "      <td>0.005230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.398092</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>0.411044</td>\n",
       "      <td>0.003642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.397712</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.412149</td>\n",
       "      <td>0.004614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.396594</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.411365</td>\n",
       "      <td>0.005617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.411550</td>\n",
       "      <td>0.004372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.395465</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.412287</td>\n",
       "      <td>0.006482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.394301</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.411366</td>\n",
       "      <td>0.005620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.394266</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.411550</td>\n",
       "      <td>0.006386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.393540</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.410904</td>\n",
       "      <td>0.006432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.393056</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.410628</td>\n",
       "      <td>0.007510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.392261</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.410398</td>\n",
       "      <td>0.007174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.391720</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>0.411135</td>\n",
       "      <td>0.006183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.390948</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.410582</td>\n",
       "      <td>0.005751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.390129</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.410859</td>\n",
       "      <td>0.005782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.389369</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.408969</td>\n",
       "      <td>0.006626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.388920</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.409476</td>\n",
       "      <td>0.006882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.379609</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>0.406572</td>\n",
       "      <td>0.010530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.379540</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>0.406571</td>\n",
       "      <td>0.008929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.379010</td>\n",
       "      <td>0.003324</td>\n",
       "      <td>0.406894</td>\n",
       "      <td>0.008953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.378411</td>\n",
       "      <td>0.002978</td>\n",
       "      <td>0.406664</td>\n",
       "      <td>0.009464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.377869</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.406019</td>\n",
       "      <td>0.009259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.377558</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>0.406480</td>\n",
       "      <td>0.008274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.377097</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>0.407263</td>\n",
       "      <td>0.007692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.376555</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.406572</td>\n",
       "      <td>0.008579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.376279</td>\n",
       "      <td>0.002617</td>\n",
       "      <td>0.407125</td>\n",
       "      <td>0.008451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.375611</td>\n",
       "      <td>0.003130</td>\n",
       "      <td>0.407493</td>\n",
       "      <td>0.008353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.375035</td>\n",
       "      <td>0.003368</td>\n",
       "      <td>0.407263</td>\n",
       "      <td>0.008701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.374470</td>\n",
       "      <td>0.003303</td>\n",
       "      <td>0.407309</td>\n",
       "      <td>0.008449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.374493</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>0.408139</td>\n",
       "      <td>0.008641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.373755</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.407355</td>\n",
       "      <td>0.009112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.374043</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.407816</td>\n",
       "      <td>0.009065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.373283</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.407678</td>\n",
       "      <td>0.007486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.373064</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.407448</td>\n",
       "      <td>0.007526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.372799</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>0.406848</td>\n",
       "      <td>0.007551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.373006</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>0.407079</td>\n",
       "      <td>0.008261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.372465</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>0.408462</td>\n",
       "      <td>0.007334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>0.407217</td>\n",
       "      <td>0.007297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.371013</td>\n",
       "      <td>0.003247</td>\n",
       "      <td>0.407632</td>\n",
       "      <td>0.006656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.370921</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.407263</td>\n",
       "      <td>0.007359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.370517</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>0.407217</td>\n",
       "      <td>0.007162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.369953</td>\n",
       "      <td>0.003045</td>\n",
       "      <td>0.407908</td>\n",
       "      <td>0.007286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.369480</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.407263</td>\n",
       "      <td>0.007284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.369008</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>0.407586</td>\n",
       "      <td>0.007480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.368870</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>0.407632</td>\n",
       "      <td>0.006644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.368732</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.407448</td>\n",
       "      <td>0.006770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.367810</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.405834</td>\n",
       "      <td>0.005997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-error-mean  train-error-std  test-error-mean  test-error-std\n",
       "0           0.421022         0.002023         0.432521        0.005487\n",
       "1           0.414835         0.001924         0.424824        0.004300\n",
       "2           0.410744         0.001292         0.422197        0.004521\n",
       "3           0.408439         0.001587         0.419846        0.006790\n",
       "4           0.406711         0.002886         0.421229        0.006079\n",
       "5           0.405651         0.001565         0.420630        0.006465\n",
       "6           0.403980         0.001476         0.421045        0.004949\n",
       "7           0.403865         0.001519         0.417911        0.005358\n",
       "8           0.401963         0.001680         0.417127        0.005718\n",
       "9           0.401618         0.001550         0.415698        0.005775\n",
       "10          0.400869         0.001608         0.415237        0.005184\n",
       "11          0.400004         0.000518         0.413486        0.003710\n",
       "12          0.399947         0.000816         0.413163        0.004833\n",
       "13          0.399843         0.001874         0.412933        0.004772\n",
       "14          0.398311         0.001761         0.412150        0.005230\n",
       "15          0.398092         0.002087         0.411044        0.003642\n",
       "16          0.397712         0.001420         0.412149        0.004614\n",
       "17          0.396594         0.001060         0.411365        0.005617\n",
       "18          0.395833         0.000773         0.411550        0.004372\n",
       "19          0.395465         0.001157         0.412287        0.006482\n",
       "20          0.394301         0.000897         0.411366        0.005620\n",
       "21          0.394266         0.001218         0.411550        0.006386\n",
       "22          0.393540         0.001013         0.410904        0.006432\n",
       "23          0.393056         0.001005         0.410628        0.007510\n",
       "24          0.392261         0.000921         0.410398        0.007174\n",
       "25          0.391720         0.001381         0.411135        0.006183\n",
       "26          0.390948         0.000985         0.410582        0.005751\n",
       "27          0.390129         0.001342         0.410859        0.005782\n",
       "28          0.389369         0.001301         0.408969        0.006626\n",
       "29          0.388920         0.001402         0.409476        0.006882\n",
       "..               ...              ...              ...             ...\n",
       "50          0.379609         0.002552         0.406572        0.010530\n",
       "51          0.379540         0.003082         0.406571        0.008929\n",
       "52          0.379010         0.003324         0.406894        0.008953\n",
       "53          0.378411         0.002978         0.406664        0.009464\n",
       "54          0.377869         0.002989         0.406019        0.009259\n",
       "55          0.377558         0.003528         0.406480        0.008274\n",
       "56          0.377097         0.003261         0.407263        0.007692\n",
       "57          0.376555         0.002581         0.406572        0.008579\n",
       "58          0.376279         0.002617         0.407125        0.008451\n",
       "59          0.375611         0.003130         0.407493        0.008353\n",
       "60          0.375035         0.003368         0.407263        0.008701\n",
       "61          0.374470         0.003303         0.407309        0.008449\n",
       "62          0.374493         0.003947         0.408139        0.008641\n",
       "63          0.373755         0.003640         0.407355        0.009112\n",
       "64          0.374043         0.003555         0.407816        0.009065\n",
       "65          0.373283         0.003086         0.407678        0.007486\n",
       "66          0.373064         0.002709         0.407448        0.007526\n",
       "67          0.372799         0.002731         0.406848        0.007551\n",
       "68          0.373006         0.002986         0.407079        0.008261\n",
       "69          0.372465         0.003325         0.408462        0.007334\n",
       "70          0.371785         0.002762         0.407217        0.007297\n",
       "71          0.371013         0.003247         0.407632        0.006656\n",
       "72          0.370921         0.002710         0.407263        0.007359\n",
       "73          0.370517         0.003034         0.407217        0.007162\n",
       "74          0.369953         0.003045         0.407908        0.007286\n",
       "75          0.369480         0.002998         0.407263        0.007284\n",
       "76          0.369008         0.003070         0.407586        0.007480\n",
       "77          0.368870         0.002882         0.407632        0.006644\n",
       "78          0.368732         0.002809         0.407448        0.006770\n",
       "79          0.367810         0.002633         0.405834        0.005997\n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=49,\n",
    "    max_depth=6,\n",
    "    min_child_weight=161,\n",
    "    gamma=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    n_jobs=-1,\n",
    "    scale_pos_weight=1,        \n",
    "    seed=0)\n",
    "\n",
    "xgb_param = xgb.get_xgb_params()\n",
    "xgtrain = xgboost.DMatrix(X_train, label=y_train)\n",
    "\n",
    "xgboost.cv(xgb_param, xgtrain, num_boost_round=5000, nfold=5, metrics=['error'],\n",
    "     early_stopping_rounds=50, stratified=True, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10 times\n",
      "Run 0 best param:  {'n_estimators': 79}\n",
      "Run 0 best score:  0.5924133480825958\n",
      "Run 1 best param:  {'n_estimators': 100}\n",
      "Run 1 best score:  0.5922289823008849\n",
      "Run 2 best param:  {'n_estimators': 100}\n",
      "Run 2 best score:  0.5899244100294986\n",
      "Run 3 best param:  {'n_estimators': 79}\n",
      "Run 3 best score:  0.59172197640118\n",
      "Run 4 best param:  {'n_estimators': 79}\n",
      "Run 4 best score:  0.592551622418879\n",
      "Run 5 best param:  {'n_estimators': 79}\n",
      "Run 5 best score:  0.5897400442477876\n",
      "Run 6 best param:  {'n_estimators': 100}\n",
      "Run 6 best score:  0.591030604719764\n",
      "Run 7 best param:  {'n_estimators': 79}\n",
      "Run 7 best score:  0.5925055309734514\n",
      "Run 8 best param:  {'n_estimators': 79}\n",
      "Run 8 best score:  0.5891408554572272\n",
      "Run 9 best param:  {'n_estimators': 79}\n",
      "Run 9 best score:  0.5900626843657817\n",
      "Best params:  params               {'n_estimators': 79}\n",
      "mean_test_score_0                0.592413\n",
      "mean_test_score_1                0.591999\n",
      "mean_test_score_2                 0.58891\n",
      "mean_test_score_3                0.591722\n",
      "mean_test_score_4                0.592552\n",
      "mean_test_score_5                 0.58974\n",
      "mean_test_score_6                0.588496\n",
      "mean_test_score_7                0.592506\n",
      "mean_test_score_8                0.589141\n",
      "mean_test_score_9                0.590063\n",
      "avg                              0.590754\n",
      "Name: 9, dtype: object\n"
     ]
    }
   ],
   "source": [
    "NUM_TRIALS = int(np.ceil(200000/train.shape[0]))\n",
    "param_test_recalibrate = {\n",
    " 'n_estimators':[i for i in range(100, 1000, 100)]+[79]\n",
    "}\n",
    "# Grid search 1 cv result\n",
    "grid_score_recalibrate = pd.DataFrame()\n",
    "\n",
    "# Loop for each trial\n",
    "print('Run {} times'.format(NUM_TRIALS))\n",
    "for i in range(NUM_TRIALS):\n",
    "    xgb = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=49,\n",
    "        max_depth=6,\n",
    "        min_child_weight=161,\n",
    "        gamma=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=1,        \n",
    "        seed=0)\n",
    "    five_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=i)\n",
    "    gsearch_recalibrate = GridSearchCV(estimator = xgb,\n",
    "                            param_grid = param_test_recalibrate,\n",
    "                            scoring='accuracy',n_jobs=-1,\n",
    "                            cv=five_folds,\n",
    "                            return_train_score=False)\n",
    "    gsearch_recalibrate.fit(X_train,y_train)    \n",
    "    if grid_score_recalibrate.empty:\n",
    "        grid_score_recalibrate = pd.DataFrame(gsearch_recalibrate.cv_results_, columns=['params', 'mean_test_score'])\n",
    "        grid_score_recalibrate.columns = ['params', 'mean_test_score_0']\n",
    "    else:\n",
    "        grid_score_recalibrate['mean_test_score_{}'.format(i)] = pd.DataFrame(gsearch_recalibrate.cv_results_).mean_test_score\n",
    "    print('Run {} best param: '.format(i), gsearch_recalibrate.best_params_)\n",
    "    print('Run {} best score: '.format(i), gsearch_recalibrate.best_score_)\n",
    "\n",
    "grid_score_recalibrate['avg'] = grid_score_recalibrate.sum(axis=1)/NUM_TRIALS\n",
    "print('Best params: ', grid_score_recalibrate.loc[grid_score_recalibrate.avg.idxmax(), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10 times\n",
      "Run 0 best param:  {'n_estimators': 50}\n",
      "Run 0 best score:  0.5933812684365781\n",
      "Run 1 best param:  {'n_estimators': 79}\n",
      "Run 1 best score:  0.5919985250737463\n",
      "Run 2 best param:  {'n_estimators': 40}\n",
      "Run 2 best score:  0.5913532448377581\n",
      "Run 3 best param:  {'n_estimators': 50}\n",
      "Run 3 best score:  0.5919985250737463\n",
      "Run 4 best param:  {'n_estimators': 79}\n",
      "Run 4 best score:  0.592551622418879\n",
      "Run 5 best param:  {'n_estimators': 50}\n",
      "Run 5 best score:  0.5908923303834809\n",
      "Run 6 best param:  {'n_estimators': 90}\n",
      "Run 6 best score:  0.5894174041297935\n",
      "Run 7 best param:  {'n_estimators': 70}\n",
      "Run 7 best score:  0.5930125368731564\n",
      "Run 8 best param:  {'n_estimators': 50}\n",
      "Run 8 best score:  0.5912610619469026\n",
      "Run 9 best param:  {'n_estimators': 50}\n",
      "Run 9 best score:  0.5932890855457227\n",
      "Best params:  params               {'n_estimators': 50}\n",
      "mean_test_score_0                0.593381\n",
      "mean_test_score_1                 0.59186\n",
      "mean_test_score_2                0.591123\n",
      "mean_test_score_3                0.591999\n",
      "mean_test_score_4                0.590385\n",
      "mean_test_score_5                0.590892\n",
      "mean_test_score_6                0.587989\n",
      "mean_test_score_7                0.592552\n",
      "mean_test_score_8                0.591261\n",
      "mean_test_score_9                0.593289\n",
      "avg                              0.591473\n",
      "Name: 4, dtype: object\n"
     ]
    }
   ],
   "source": [
    "NUM_TRIALS = int(np.ceil(200000/train.shape[0]))\n",
    "param_test_recalibrateb = {\n",
    " 'n_estimators':[i for i in range(10, 100, 10)]+[79]\n",
    "}\n",
    "# Grid search 1 cv result\n",
    "grid_score_recalibrateb = pd.DataFrame()\n",
    "\n",
    "# Loop for each trial\n",
    "print('Run {} times'.format(NUM_TRIALS))\n",
    "for i in range(NUM_TRIALS):\n",
    "    xgb = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=79,\n",
    "        max_depth=6,\n",
    "        min_child_weight=161,\n",
    "        gamma=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=1,        \n",
    "        seed=0)\n",
    "    five_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=i)\n",
    "    gsearch_recalibrateb = GridSearchCV(estimator = xgb,\n",
    "                            param_grid = param_test_recalibrateb,\n",
    "                            scoring='accuracy',n_jobs=-1,\n",
    "                            cv=five_folds,\n",
    "                            return_train_score=False)\n",
    "    gsearch_recalibrateb.fit(X_train,y_train)    \n",
    "    if grid_score_recalibrateb.empty:\n",
    "        grid_score_recalibrateb = pd.DataFrame(gsearch_recalibrateb.cv_results_, columns=['params', 'mean_test_score'])\n",
    "        grid_score_recalibrateb.columns = ['params', 'mean_test_score_0']\n",
    "    else:\n",
    "        grid_score_recalibrateb['mean_test_score_{}'.format(i)] = pd.DataFrame(gsearch_recalibrateb.cv_results_).mean_test_score\n",
    "    print('Run {} best param: '.format(i), gsearch_recalibrateb.best_params_)\n",
    "    print('Run {} best score: '.format(i), gsearch_recalibrateb.best_score_)\n",
    "\n",
    "grid_score_recalibrateb['avg'] = grid_score_recalibrateb.sum(axis=1)/NUM_TRIALS\n",
    "print('Best params: ', grid_score_recalibrateb.loc[grid_score_recalibrateb.avg.idxmax(), :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10 times\n",
      "Run 0 best param:  {'colsample_bytree': 0.8, 'subsample': 0.8}\n",
      "Run 0 best score:  0.5933812684365781\n",
      "Run 1 best param:  {'colsample_bytree': 0.6, 'subsample': 0.8}\n",
      "Run 1 best score:  0.5927359882005899\n",
      "Run 2 best param:  {'colsample_bytree': 0.9, 'subsample': 0.9}\n",
      "Run 2 best score:  0.5938421828908554\n",
      "Run 3 best param:  {'colsample_bytree': 0.8, 'subsample': 0.8}\n",
      "Run 3 best score:  0.5919985250737463\n",
      "Run 4 best param:  {'colsample_bytree': 0.6, 'subsample': 0.9}\n",
      "Run 4 best score:  0.5946718289085545\n",
      "Run 5 best param:  {'colsample_bytree': 0.7, 'subsample': 0.8}\n",
      "Run 5 best score:  0.5912610619469026\n",
      "Run 6 best param:  {'colsample_bytree': 0.7, 'subsample': 0.9}\n",
      "Run 6 best score:  0.5928742625368731\n",
      "Run 7 best param:  {'colsample_bytree': 0.8, 'subsample': 0.9}\n",
      "Run 7 best score:  0.5935656342182891\n",
      "Run 8 best param:  {'colsample_bytree': 0.7, 'subsample': 0.9}\n",
      "Run 8 best score:  0.5927820796460177\n",
      "Run 9 best param:  {'colsample_bytree': 0.8, 'subsample': 0.8}\n",
      "Run 9 best score:  0.5932890855457227\n",
      "Best params:  params               {'colsample_bytree': 0.8, 'subsample': 0.8}\n",
      "mean_test_score_0                                       0.593381\n",
      "mean_test_score_1                                        0.59186\n",
      "mean_test_score_2                                       0.591123\n",
      "mean_test_score_3                                       0.591999\n",
      "mean_test_score_4                                       0.590385\n",
      "mean_test_score_5                                       0.590892\n",
      "mean_test_score_6                                       0.587989\n",
      "mean_test_score_7                                       0.592552\n",
      "mean_test_score_8                                       0.591261\n",
      "mean_test_score_9                                       0.593289\n",
      "avg                                                     0.591473\n",
      "Name: 10, dtype: object\n"
     ]
    }
   ],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "# Grid search 1 cv result\n",
    "grid_score4 = pd.DataFrame()\n",
    "\n",
    "# Loop for each trial\n",
    "print('Run {} times'.format(NUM_TRIALS))\n",
    "for i in range(NUM_TRIALS):\n",
    "    xgb = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=50,\n",
    "        max_depth=6,\n",
    "        min_child_weight=161,\n",
    "        gamma=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=1,        \n",
    "        seed=0)\n",
    "    five_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=i)\n",
    "    gsearch4 = GridSearchCV(estimator = xgb,\n",
    "                            param_grid = param_test4,\n",
    "                            scoring='accuracy',n_jobs=-1,\n",
    "                            cv=five_folds,\n",
    "                            return_train_score=False)\n",
    "    gsearch4.fit(X_train,y_train)    \n",
    "    if grid_score4.empty:\n",
    "        grid_score4 = pd.DataFrame(gsearch4.cv_results_, columns=['params', 'mean_test_score'])\n",
    "        grid_score4.columns = ['params', 'mean_test_score_0']\n",
    "    else:\n",
    "        grid_score4['mean_test_score_{}'.format(i)] = pd.DataFrame(gsearch4.cv_results_).mean_test_score\n",
    "    print('Run {} best param: '.format(i), gsearch4.best_params_)\n",
    "    print('Run {} best score: '.format(i), gsearch4.best_score_)\n",
    "\n",
    "grid_score4['avg'] = grid_score4.sum(axis=1)/NUM_TRIALS\n",
    "print('Best params: ', grid_score4.loc[grid_score4.avg.idxmax(), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10 times\n",
      "Run 0 best param:  {'colsample_bytree': 0.85, 'subsample': 0.85}\n",
      "Run 0 best score:  0.594257005899705\n",
      "Run 1 best param:  {'colsample_bytree': 0.85, 'subsample': 0.75}\n",
      "Run 1 best score:  0.5928281710914455\n",
      "Run 2 best param:  {'colsample_bytree': 0.75, 'subsample': 0.8}\n",
      "Run 2 best score:  0.5929203539823009\n",
      "Run 3 best param:  {'colsample_bytree': 0.75, 'subsample': 0.75}\n",
      "Run 3 best score:  0.5924594395280236\n",
      "Run 4 best param:  {'colsample_bytree': 0.75, 'subsample': 0.8}\n",
      "Run 4 best score:  0.5940265486725663\n",
      "Run 5 best param:  {'colsample_bytree': 0.8, 'subsample': 0.8}\n",
      "Run 5 best score:  0.5908923303834809\n",
      "Run 6 best param:  {'colsample_bytree': 0.8, 'subsample': 0.85}\n",
      "Run 6 best score:  0.590016592920354\n",
      "Run 7 best param:  {'colsample_bytree': 0.8, 'subsample': 0.8}\n",
      "Run 7 best score:  0.592551622418879\n",
      "Run 8 best param:  {'colsample_bytree': 0.85, 'subsample': 0.8}\n",
      "Run 8 best score:  0.5918141592920354\n",
      "Run 9 best param:  {'colsample_bytree': 0.8, 'subsample': 0.8}\n",
      "Run 9 best score:  0.5932890855457227\n",
      "Best params:  params               {'colsample_bytree': 0.8, 'subsample': 0.8}\n",
      "mean_test_score_0                                       0.593381\n",
      "mean_test_score_1                                        0.59186\n",
      "mean_test_score_2                                       0.591123\n",
      "mean_test_score_3                                       0.591999\n",
      "mean_test_score_4                                       0.590385\n",
      "mean_test_score_5                                       0.590892\n",
      "mean_test_score_6                                       0.587989\n",
      "mean_test_score_7                                       0.592552\n",
      "mean_test_score_8                                       0.591261\n",
      "mean_test_score_9                                       0.593289\n",
      "avg                                                     0.591473\n",
      "Name: 4, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Carefully search for each neighboring 0.05\n",
    "param_test5 = {\n",
    " 'subsample':[i/100.0 for i in range(75,86,5)],\n",
    " 'colsample_bytree':[i/100.0 for i in range(75,86,5)]\n",
    "}\n",
    "# Grid search 1 cv result\n",
    "grid_score5 = pd.DataFrame()\n",
    "\n",
    "# Loop for each trial\n",
    "print('Run {} times'.format(NUM_TRIALS))\n",
    "for i in range(NUM_TRIALS):\n",
    "    xgb = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=50,\n",
    "        max_depth=6,\n",
    "        min_child_weight=161,\n",
    "        gamma=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=1,        \n",
    "        seed=0)\n",
    "    five_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=i)\n",
    "    gsearch5 = GridSearchCV(estimator = xgb,\n",
    "                            param_grid = param_test5,\n",
    "                            scoring='accuracy',n_jobs=-1,\n",
    "                            cv=five_folds,\n",
    "                            return_train_score=False)\n",
    "    gsearch5.fit(X_train,y_train)    \n",
    "    if grid_score5.empty:\n",
    "        grid_score5 = pd.DataFrame(gsearch5.cv_results_, columns=['params', 'mean_test_score'])\n",
    "        grid_score5.columns = ['params', 'mean_test_score_0']\n",
    "    else:\n",
    "        grid_score5['mean_test_score_{}'.format(i)] = pd.DataFrame(gsearch5.cv_results_).mean_test_score\n",
    "    print('Run {} best param: '.format(i), gsearch5.best_params_)\n",
    "    print('Run {} best score: '.format(i), gsearch5.best_score_)\n",
    "\n",
    "grid_score5['avg'] = grid_score5.sum(axis=1)/NUM_TRIALS\n",
    "print('Best params: ', grid_score5.loc[grid_score5.avg.idxmax(), :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Regularization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10 times\n",
      "Run 0 best param:  {'reg_alpha': 0}\n",
      "Run 0 best score:  0.5933812684365781\n",
      "Run 1 best param:  {'reg_alpha': 0}\n",
      "Run 1 best score:  0.5918602507374632\n",
      "Run 2 best param:  {'reg_alpha': 1}\n",
      "Run 2 best score:  0.5922289823008849\n",
      "Run 3 best param:  {'reg_alpha': 0}\n",
      "Run 3 best score:  0.5919985250737463\n",
      "Run 4 best param:  {'reg_alpha': 0.1}\n",
      "Run 4 best score:  0.5936117256637168\n",
      "Run 5 best param:  {'reg_alpha': 1}\n",
      "Run 5 best score:  0.5915376106194691\n",
      "Run 6 best param:  {'reg_alpha': 0.01}\n",
      "Run 6 best score:  0.589002581120944\n",
      "Run 7 best param:  {'reg_alpha': 0}\n",
      "Run 7 best score:  0.592551622418879\n",
      "Run 8 best param:  {'reg_alpha': 0.1}\n",
      "Run 8 best score:  0.5921828908554573\n",
      "Run 9 best param:  {'reg_alpha': 0}\n",
      "Run 9 best score:  0.5932890855457227\n",
      "Best params:  params               {'reg_alpha': 0}\n",
      "mean_test_score_0            0.593381\n",
      "mean_test_score_1             0.59186\n",
      "mean_test_score_2            0.591123\n",
      "mean_test_score_3            0.591999\n",
      "mean_test_score_4            0.590385\n",
      "mean_test_score_5            0.590892\n",
      "mean_test_score_6            0.587989\n",
      "mean_test_score_7            0.592552\n",
      "mean_test_score_8            0.591261\n",
      "mean_test_score_9            0.593289\n",
      "avg                          0.591473\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "param_test6 = {\n",
    " 'reg_alpha':[0, 1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "# Grid search 1 cv result\n",
    "grid_score6 = pd.DataFrame()\n",
    "\n",
    "# Loop for each trial\n",
    "print('Run {} times'.format(NUM_TRIALS))\n",
    "for i in range(NUM_TRIALS):\n",
    "    xgb = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=50,\n",
    "        max_depth=6,\n",
    "        min_child_weight=161,\n",
    "        gamma=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=1,        \n",
    "        seed=0)\n",
    "    five_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=i)\n",
    "    gsearch6 = GridSearchCV(estimator = xgb,\n",
    "                            param_grid = param_test6,\n",
    "                            scoring='accuracy',n_jobs=-1,\n",
    "                            cv=five_folds,\n",
    "                            return_train_score=False)\n",
    "    gsearch6.fit(X_train,y_train)    \n",
    "    if grid_score6.empty:\n",
    "        grid_score6 = pd.DataFrame(gsearch6.cv_results_, columns=['params', 'mean_test_score'])\n",
    "        grid_score6.columns = ['params', 'mean_test_score_0']\n",
    "    else:\n",
    "        grid_score6['mean_test_score_{}'.format(i)] = pd.DataFrame(gsearch6.cv_results_).mean_test_score\n",
    "    print('Run {} best param: '.format(i), gsearch6.best_params_)\n",
    "    print('Run {} best score: '.format(i), gsearch6.best_score_)\n",
    "\n",
    "grid_score6['avg'] = grid_score6.sum(axis=1)/NUM_TRIALS\n",
    "print('Best params: ', grid_score6.loc[grid_score6.avg.idxmax(), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10 times\n",
      "Run 0 best param:  {'reg_alpha': 0}\n",
      "Run 0 best score:  0.5933812684365781\n",
      "Run 1 best param:  {'reg_alpha': 0}\n",
      "Run 1 best score:  0.5918602507374632\n",
      "Run 2 best param:  {'reg_alpha': 0}\n",
      "Run 2 best score:  0.5911227876106194\n",
      "Run 3 best param:  {'reg_alpha': 0}\n",
      "Run 3 best score:  0.5919985250737463\n",
      "Run 4 best param:  {'reg_alpha': 0}\n",
      "Run 4 best score:  0.5903853244837758\n",
      "Run 5 best param:  {'reg_alpha': 0}\n",
      "Run 5 best score:  0.5908923303834809\n",
      "Run 6 best param:  {'reg_alpha': 0.0005}\n",
      "Run 6 best score:  0.5880346607669616\n",
      "Run 7 best param:  {'reg_alpha': 0}\n",
      "Run 7 best score:  0.592551622418879\n",
      "Run 8 best param:  {'reg_alpha': 0}\n",
      "Run 8 best score:  0.5912610619469026\n",
      "Run 9 best param:  {'reg_alpha': 0}\n",
      "Run 9 best score:  0.5932890855457227\n",
      "Best params:  params               {'reg_alpha': 0.0005}\n",
      "mean_test_score_0                 0.593381\n",
      "mean_test_score_1                  0.59186\n",
      "mean_test_score_2                 0.591123\n",
      "mean_test_score_3                 0.591999\n",
      "mean_test_score_4                 0.590385\n",
      "mean_test_score_5                 0.590892\n",
      "mean_test_score_6                 0.588035\n",
      "mean_test_score_7                 0.592552\n",
      "mean_test_score_8                 0.591261\n",
      "mean_test_score_9                 0.593289\n",
      "avg                               0.591478\n",
      "Name: 5, dtype: object\n"
     ]
    }
   ],
   "source": [
    "param_test7 = {\n",
    " 'reg_alpha':[0, 1e-6, 5e-6, 5e-5, 1e-4, 5e-4]\n",
    "}\n",
    "# Grid search 1 cv result\n",
    "grid_score7 = pd.DataFrame()\n",
    "\n",
    "# Loop for each trial\n",
    "print('Run {} times'.format(NUM_TRIALS))\n",
    "for i in range(NUM_TRIALS):\n",
    "    xgb = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=50,\n",
    "        max_depth=6,\n",
    "        min_child_weight=161,\n",
    "        gamma=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=1,        \n",
    "        seed=0)\n",
    "    five_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=i)\n",
    "    gsearch7 = GridSearchCV(estimator = xgb,\n",
    "                            param_grid = param_test7,\n",
    "                            scoring='accuracy',n_jobs=-1,\n",
    "                            cv=five_folds,\n",
    "                            return_train_score=False)\n",
    "    gsearch7.fit(X_train,y_train)    \n",
    "    if grid_score7.empty:\n",
    "        grid_score7 = pd.DataFrame(gsearch7.cv_results_, columns=['params', 'mean_test_score'])\n",
    "        grid_score7.columns = ['params', 'mean_test_score_0']\n",
    "    else:\n",
    "        grid_score7['mean_test_score_{}'.format(i)] = pd.DataFrame(gsearch7.cv_results_).mean_test_score\n",
    "    print('Run {} best param: '.format(i), gsearch7.best_params_)\n",
    "    print('Run {} best score: '.format(i), gsearch7.best_score_)\n",
    "\n",
    "grid_score7['avg'] = grid_score7.sum(axis=1)/NUM_TRIALS\n",
    "print('Best params: ', grid_score7.loc[grid_score7.avg.idxmax(), :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce the learning rate and tune n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.421022</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.432521</td>\n",
       "      <td>0.005487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.416989</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>0.426483</td>\n",
       "      <td>0.006825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.414512</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.423257</td>\n",
       "      <td>0.005936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.412207</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.421736</td>\n",
       "      <td>0.003281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.411539</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.421460</td>\n",
       "      <td>0.005557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.410410</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.422289</td>\n",
       "      <td>0.004668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.410617</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.422382</td>\n",
       "      <td>0.005791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.409476</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>0.422243</td>\n",
       "      <td>0.006696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.409165</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.422244</td>\n",
       "      <td>0.006260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.407875</td>\n",
       "      <td>0.002117</td>\n",
       "      <td>0.422520</td>\n",
       "      <td>0.005837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.408520</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>0.421137</td>\n",
       "      <td>0.006743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.408117</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.420077</td>\n",
       "      <td>0.004267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.407863</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.419616</td>\n",
       "      <td>0.005053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.407978</td>\n",
       "      <td>0.002286</td>\n",
       "      <td>0.419754</td>\n",
       "      <td>0.004701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.406769</td>\n",
       "      <td>0.002805</td>\n",
       "      <td>0.419340</td>\n",
       "      <td>0.003862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.407391</td>\n",
       "      <td>0.002241</td>\n",
       "      <td>0.419109</td>\n",
       "      <td>0.004526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.407091</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>0.419570</td>\n",
       "      <td>0.004658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.407322</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>0.419754</td>\n",
       "      <td>0.006455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.406815</td>\n",
       "      <td>0.003076</td>\n",
       "      <td>0.419801</td>\n",
       "      <td>0.005731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.406918</td>\n",
       "      <td>0.002832</td>\n",
       "      <td>0.418833</td>\n",
       "      <td>0.005601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.406457</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>0.418326</td>\n",
       "      <td>0.004461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.406815</td>\n",
       "      <td>0.002136</td>\n",
       "      <td>0.417312</td>\n",
       "      <td>0.004990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.406884</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>0.417818</td>\n",
       "      <td>0.005414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.406273</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.418510</td>\n",
       "      <td>0.005350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.406100</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>0.418049</td>\n",
       "      <td>0.005529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.406192</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>0.418049</td>\n",
       "      <td>0.006147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.405801</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>0.417312</td>\n",
       "      <td>0.006218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.405939</td>\n",
       "      <td>0.002617</td>\n",
       "      <td>0.417265</td>\n",
       "      <td>0.006066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.405570</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.416528</td>\n",
       "      <td>0.006673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.405409</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.416897</td>\n",
       "      <td>0.006425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>0.380381</td>\n",
       "      <td>0.001722</td>\n",
       "      <td>0.407263</td>\n",
       "      <td>0.009077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>0.380243</td>\n",
       "      <td>0.001836</td>\n",
       "      <td>0.407355</td>\n",
       "      <td>0.009120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>0.380323</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.407355</td>\n",
       "      <td>0.009055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>0.380243</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.407355</td>\n",
       "      <td>0.008965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>0.380082</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.407447</td>\n",
       "      <td>0.009063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>0.380301</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.407309</td>\n",
       "      <td>0.008634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>0.380185</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>0.407263</td>\n",
       "      <td>0.008676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0.380059</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>0.407309</td>\n",
       "      <td>0.008550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>0.379955</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.407217</td>\n",
       "      <td>0.008717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>0.379886</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.407171</td>\n",
       "      <td>0.008764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>0.379678</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>0.407309</td>\n",
       "      <td>0.008681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0.379667</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.407586</td>\n",
       "      <td>0.008488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0.379885</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>0.407217</td>\n",
       "      <td>0.008486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0.379794</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.407079</td>\n",
       "      <td>0.008442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>0.379609</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.407447</td>\n",
       "      <td>0.008526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>0.379563</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.407585</td>\n",
       "      <td>0.008692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0.379574</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.407355</td>\n",
       "      <td>0.008395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0.379494</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.407447</td>\n",
       "      <td>0.008642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0.379471</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.407217</td>\n",
       "      <td>0.008751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0.379436</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.407309</td>\n",
       "      <td>0.008739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.379448</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>0.407448</td>\n",
       "      <td>0.008777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.379240</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>0.407309</td>\n",
       "      <td>0.008766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.379114</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>0.407401</td>\n",
       "      <td>0.008919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.379021</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.407493</td>\n",
       "      <td>0.009221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.378929</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.407263</td>\n",
       "      <td>0.009198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0.378998</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.407125</td>\n",
       "      <td>0.008821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0.379044</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>0.407217</td>\n",
       "      <td>0.009095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0.378952</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.407355</td>\n",
       "      <td>0.008866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0.378883</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>0.407171</td>\n",
       "      <td>0.009059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0.378918</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.406894</td>\n",
       "      <td>0.009141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>484 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     train-error-mean  train-error-std  test-error-mean  test-error-std\n",
       "0            0.421022         0.002023         0.432521        0.005487\n",
       "1            0.416989         0.002263         0.426483        0.006825\n",
       "2            0.414512         0.002853         0.423257        0.005936\n",
       "3            0.412207         0.001913         0.421736        0.003281\n",
       "4            0.411539         0.002062         0.421460        0.005557\n",
       "5            0.410410         0.001800         0.422289        0.004668\n",
       "6            0.410617         0.001390         0.422382        0.005791\n",
       "7            0.409476         0.002545         0.422243        0.006696\n",
       "8            0.409165         0.002597         0.422244        0.006260\n",
       "9            0.407875         0.002117         0.422520        0.005837\n",
       "10           0.408520         0.002441         0.421137        0.006743\n",
       "11           0.408117         0.001915         0.420077        0.004267\n",
       "12           0.407863         0.002002         0.419616        0.005053\n",
       "13           0.407978         0.002286         0.419754        0.004701\n",
       "14           0.406769         0.002805         0.419340        0.003862\n",
       "15           0.407391         0.002241         0.419109        0.004526\n",
       "16           0.407091         0.002653         0.419570        0.004658\n",
       "17           0.407322         0.001946         0.419754        0.006455\n",
       "18           0.406815         0.003076         0.419801        0.005731\n",
       "19           0.406918         0.002832         0.418833        0.005601\n",
       "20           0.406457         0.002558         0.418326        0.004461\n",
       "21           0.406815         0.002136         0.417312        0.004990\n",
       "22           0.406884         0.002594         0.417818        0.005414\n",
       "23           0.406273         0.002428         0.418510        0.005350\n",
       "24           0.406100         0.002113         0.418049        0.005529\n",
       "25           0.406192         0.002488         0.418049        0.006147\n",
       "26           0.405801         0.001946         0.417312        0.006218\n",
       "27           0.405939         0.002617         0.417265        0.006066\n",
       "28           0.405570         0.002179         0.416528        0.006673\n",
       "29           0.405409         0.002258         0.416897        0.006425\n",
       "..                ...              ...              ...             ...\n",
       "454          0.380381         0.001722         0.407263        0.009077\n",
       "455          0.380243         0.001836         0.407355        0.009120\n",
       "456          0.380323         0.001734         0.407355        0.009055\n",
       "457          0.380243         0.001764         0.407355        0.008965\n",
       "458          0.380082         0.001790         0.407447        0.009063\n",
       "459          0.380301         0.001708         0.407309        0.008634\n",
       "460          0.380185         0.001756         0.407263        0.008676\n",
       "461          0.380059         0.001639         0.407309        0.008550\n",
       "462          0.379955         0.001565         0.407217        0.008717\n",
       "463          0.379886         0.001633         0.407171        0.008764\n",
       "464          0.379678         0.001559         0.407309        0.008681\n",
       "465          0.379667         0.001519         0.407586        0.008488\n",
       "466          0.379885         0.001531         0.407217        0.008486\n",
       "467          0.379794         0.001366         0.407079        0.008442\n",
       "468          0.379609         0.001298         0.407447        0.008526\n",
       "469          0.379563         0.001487         0.407585        0.008692\n",
       "470          0.379574         0.001388         0.407355        0.008395\n",
       "471          0.379494         0.001350         0.407447        0.008642\n",
       "472          0.379471         0.001704         0.407217        0.008751\n",
       "473          0.379436         0.001683         0.407309        0.008739\n",
       "474          0.379448         0.001830         0.407448        0.008777\n",
       "475          0.379240         0.001891         0.407309        0.008766\n",
       "476          0.379114         0.001816         0.407401        0.008919\n",
       "477          0.379021         0.001873         0.407493        0.009221\n",
       "478          0.378929         0.001926         0.407263        0.009198\n",
       "479          0.378998         0.001968         0.407125        0.008821\n",
       "480          0.379044         0.001884         0.407217        0.009095\n",
       "481          0.378952         0.002011         0.407355        0.008866\n",
       "482          0.378883         0.001844         0.407171        0.009059\n",
       "483          0.378918         0.001878         0.406894        0.009141\n",
       "\n",
       "[484 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    learning_rate =0.01,\n",
    "    n_estimators=50,\n",
    "    max_depth=6,\n",
    "    min_child_weight=161,\n",
    "    gamma=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha = 5e-4,\n",
    "    objective= 'binary:logistic',\n",
    "    n_jobs=-1,\n",
    "    scale_pos_weight=1,        \n",
    "    seed=0)\n",
    "\n",
    "xgb_param = xgb.get_xgb_params()\n",
    "xgtrain = xgboost.DMatrix(X_train, label=y_train)\n",
    "\n",
    "xgboost.cv(xgb_param, xgtrain, num_boost_round=5000, nfold=5, metrics=['error'],\n",
    "     early_stopping_rounds=50, stratified=True, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10 times\n",
      "Run 0 best param:  {'n_estimators': 600}\n",
      "Run 0 best score:  0.5930125368731564\n",
      "Run 1 best param:  {'n_estimators': 600}\n",
      "Run 1 best score:  0.5927359882005899\n",
      "Run 2 best param:  {'n_estimators': 700}\n",
      "Run 2 best score:  0.5927820796460177\n",
      "Run 3 best param:  {'n_estimators': 1200}\n",
      "Run 3 best score:  0.5927359882005899\n",
      "Run 4 best param:  {'n_estimators': 1100}\n",
      "Run 4 best score:  0.5928281710914455\n",
      "Run 5 best param:  {'n_estimators': 1400}\n",
      "Run 5 best score:  0.5916758849557522\n",
      "Run 6 best param:  {'n_estimators': 1400}\n",
      "Run 6 best score:  0.5921828908554573\n",
      "Run 7 best param:  {'n_estimators': 483}\n",
      "Run 7 best score:  0.5920446165191741\n",
      "Run 8 best param:  {'n_estimators': 1400}\n",
      "Run 8 best score:  0.5939804572271387\n",
      "Run 9 best param:  {'n_estimators': 1200}\n",
      "Run 9 best score:  0.5916758849557522\n",
      "Best params:  params               {'n_estimators': 700}\n",
      "mean_test_score_0                 0.592598\n",
      "mean_test_score_1                 0.592552\n",
      "mean_test_score_2                 0.592782\n",
      "mean_test_score_3                 0.592598\n",
      "mean_test_score_4                 0.592367\n",
      "mean_test_score_5                 0.591307\n",
      "mean_test_score_6                 0.590431\n",
      "mean_test_score_7                 0.591169\n",
      "mean_test_score_8                 0.592552\n",
      "mean_test_score_9                 0.590938\n",
      "avg                               0.591929\n",
      "Name: 6, dtype: object\n"
     ]
    }
   ],
   "source": [
    "NUM_TRIALS = int(np.ceil(200000/train.shape[0]))\n",
    "param_test8 = {\n",
    " 'n_estimators':[i for i in range(100, 1500, 100)]+[483]\n",
    "}\n",
    "# Grid search 1 cv result\n",
    "grid_score8 = pd.DataFrame()\n",
    "\n",
    "# Loop for each trial\n",
    "print('Run {} times'.format(NUM_TRIALS))\n",
    "for i in range(NUM_TRIALS):\n",
    "    xgb = XGBClassifier(\n",
    "        learning_rate =0.01,\n",
    "        n_estimators=50,\n",
    "        max_depth=6,\n",
    "        min_child_weight=161,\n",
    "        gamma=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha = 5e-4,\n",
    "        objective= 'binary:logistic',\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=1,        \n",
    "        seed=0)\n",
    "    five_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=i)\n",
    "    gsearch8 = GridSearchCV(estimator = xgb,\n",
    "                            param_grid = param_test8,\n",
    "                            scoring='accuracy',n_jobs=-1,\n",
    "                            cv=five_folds,\n",
    "                            return_train_score=False)\n",
    "    gsearch8.fit(X_train,y_train)    \n",
    "    if grid_score8.empty:\n",
    "        grid_score8 = pd.DataFrame(gsearch8.cv_results_, columns=['params', 'mean_test_score'])\n",
    "        grid_score8.columns = ['params', 'mean_test_score_0']\n",
    "    else:\n",
    "        grid_score8['mean_test_score_{}'.format(i)] = pd.DataFrame(gsearch8.cv_results_).mean_test_score\n",
    "    print('Run {} best param: '.format(i), gsearch8.best_params_)\n",
    "    print('Run {} best score: '.format(i), gsearch8.best_score_)\n",
    "\n",
    "grid_score8['avg'] = grid_score8.sum(axis=1)/NUM_TRIALS\n",
    "print('Best params: ', grid_score8.loc[grid_score8.avg.idxmax(), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10 times\n",
      "Run 0 best param:  {'n_estimators': 680}\n",
      "Run 0 best score:  0.5926898967551623\n",
      "Run 1 best param:  {'n_estimators': 650}\n",
      "Run 1 best score:  0.5931508112094396\n",
      "Run 2 best param:  {'n_estimators': 690}\n",
      "Run 2 best score:  0.5931508112094396\n",
      "Run 3 best param:  {'n_estimators': 650}\n",
      "Run 3 best score:  0.5932890855457227\n",
      "Run 4 best param:  {'n_estimators': 670}\n",
      "Run 4 best score:  0.5928281710914455\n",
      "Run 5 best param:  {'n_estimators': 660}\n",
      "Run 5 best score:  0.5917680678466076\n",
      "Run 6 best param:  {'n_estimators': 650}\n",
      "Run 6 best score:  0.5914454277286135\n",
      "Run 7 best param:  {'n_estimators': 670}\n",
      "Run 7 best score:  0.5916758849557522\n",
      "Run 8 best param:  {'n_estimators': 710}\n",
      "Run 8 best score:  0.5933812684365781\n",
      "Run 9 best param:  {'n_estimators': 740}\n",
      "Run 9 best score:  0.5916758849557522\n",
      "Best params:  params               {'n_estimators': 650}\n",
      "mean_test_score_0                 0.591999\n",
      "mean_test_score_1                 0.593151\n",
      "mean_test_score_2                 0.592045\n",
      "mean_test_score_3                 0.593289\n",
      "mean_test_score_4                 0.592552\n",
      "mean_test_score_5                 0.591077\n",
      "mean_test_score_6                 0.591445\n",
      "mean_test_score_7                 0.591307\n",
      "mean_test_score_8                 0.592506\n",
      "mean_test_score_9                 0.591169\n",
      "avg                               0.592054\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "NUM_TRIALS = int(np.ceil(200000/train.shape[0]))\n",
    "param_test8 = {\n",
    " 'n_estimators':[i for i in range(650, 751, 10)]\n",
    "}\n",
    "# Grid search 1 cv result\n",
    "grid_score8 = pd.DataFrame()\n",
    "\n",
    "# Loop for each trial\n",
    "print('Run {} times'.format(NUM_TRIALS))\n",
    "for i in range(NUM_TRIALS):\n",
    "    xgb = XGBClassifier(\n",
    "        learning_rate =0.01,\n",
    "        n_estimators=50,\n",
    "        max_depth=6,\n",
    "        min_child_weight=161,\n",
    "        gamma=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha = 5e-4,\n",
    "        objective= 'binary:logistic',\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=1,        \n",
    "        seed=0)\n",
    "    five_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=i)\n",
    "    gsearch8 = GridSearchCV(estimator = xgb,\n",
    "                            param_grid = param_test8,\n",
    "                            scoring='accuracy',n_jobs=-1,\n",
    "                            cv=five_folds,\n",
    "                            return_train_score=False)\n",
    "    gsearch8.fit(X_train,y_train)    \n",
    "    if grid_score8.empty:\n",
    "        grid_score8 = pd.DataFrame(gsearch8.cv_results_, columns=['params', 'mean_test_score'])\n",
    "        grid_score8.columns = ['params', 'mean_test_score_0']\n",
    "    else:\n",
    "        grid_score8['mean_test_score_{}'.format(i)] = pd.DataFrame(gsearch8.cv_results_).mean_test_score\n",
    "    print('Run {} best param: '.format(i), gsearch8.best_params_)\n",
    "    print('Run {} best score: '.format(i), gsearch8.best_score_)\n",
    "\n",
    "grid_score8['avg'] = grid_score8.sum(axis=1)/NUM_TRIALS\n",
    "print('Best params: ', grid_score8.loc[grid_score8.avg.idxmax(), :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 Test on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0: 59.78%\n",
      "Accuracy 1: 59.71%\n",
      "Accuracy 2: 59.72%\n",
      "Accuracy 3: 59.72%\n",
      "Accuracy 4: 59.69%\n",
      "Accuracy 5: 59.70%\n",
      "Accuracy 6: 59.71%\n",
      "Accuracy 7: 59.73%\n",
      "Accuracy 8: 59.59%\n",
      "Accuracy 9: 59.74%\n",
      "Average accuracy is: 59.71%\n"
     ]
    }
   ],
   "source": [
    "accuracy_array = []\n",
    "for i in range(NUM_TRIALS):\n",
    "    xgb = XGBClassifier(\n",
    "        learning_rate =0.01,\n",
    "        n_estimators=650,\n",
    "        max_depth=6,\n",
    "        min_child_weight=161,\n",
    "        gamma=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha = 5e-4,\n",
    "        objective= 'binary:logistic',\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=1,\n",
    "        seed=i\n",
    "    )\n",
    "    model = xgb.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_array.append(accuracy)\n",
    "    print('Accuracy {}: %.2f%%'.format(i) % (accuracy * 100.0))\n",
    "mean_accuracy_score = sum(accuracy_array) / NUM_TRIALS\n",
    "print('Average accuracy is: %.2f%%' % (mean_accuracy_score * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
